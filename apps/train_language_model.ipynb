{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "s6RMvCP-6EeO"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pGp2do8C6EeO"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "!mkdir -p '../data/ptb'\n",
        "# Download Penn Treebank dataset\n",
        "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
        "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
        "    if not os.path.exists(os.path.join('../data/ptb', f)):\n",
        "        urllib.request.urlretrieve(ptb_data + f, os.path.join('../data/ptb', f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# openmp settings for cpu \n",
        "\"\"\"\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = \"10\"    # physical core number of 1 cpu socket\n",
        "os.environ['GOMP_CPU_AFFINITY'] = \"0-9\"    # bind thread to specific processor\n",
        "os.environ['OMP_PROC_BIND'] = \"CLOSE\"   # dont move thread between processor\n",
        "os.environ['OMP_SCHEDULE'] = \"STATIC\"\n",
        "device = ndl.cpu()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method BackendDevice.enabled of cuda()>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "```\n",
        "git clone --recursive https://github.com/wzbitl/needle.git\n",
        "cd needle\n",
        "mkdir build\n",
        "cd build\n",
        "cmake ..\n",
        "make -j $(nproc)\n",
        "```\n",
        "This will generate the corresponding CPU and GPU (if you have a NV GPU device) library files in the `/python/needle/backend_ndarray` folder.\n",
        "\n",
        "Then, if you want to continue development based on this repository, you can set the environment variable *PYTHONPATH* to tell python where to find the python library. This helps you get immediate influences when change code and rebuild.\n",
        "\n",
        "```\n",
        "export NEEDLE_HOME=/path/to/needle    # for example /home/user/needle\n",
        "export PYTHONPATH=$NEEDLE_HOME/python:${PYTHONPATH}\n",
        "```\n",
        "Or you can install Needle python package by setup.py:\n",
        "```\n",
        "cd python\n",
        "python setup.py install --user\n",
        "cd ..\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzAgSLdB6EfG",
        "outputId": "8f9424d1-b0eb-4279-908d-05cc1f0d8ae2"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m train_data = ndl.data.batchify(corpus.train, batch_size=\u001b[32m16\u001b[39m, device=device, dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m model = LanguageModel(\u001b[32m30\u001b[39m, \u001b[38;5;28mlen\u001b[39m(corpus.dictionary), hidden_size=\u001b[32m10\u001b[39m, num_layers=\u001b[32m2\u001b[39m, seq_model=\u001b[33m'\u001b[39m\u001b[33mrnn\u001b[39m\u001b[33m'\u001b[39m, device=device)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrain_ptb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m evaluate_ptb(model, train_data, seq_len=\u001b[32m40\u001b[39m, device=device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/simple_training.py:185\u001b[39m, in \u001b[36mtrain_ptb\u001b[39m\u001b[34m(model, data, seq_len, n_epochs, optimizer, lr, weight_decay, loss_fn, clip, device, dtype)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_ptb\u001b[39m(model, data, seq_len=\u001b[32m40\u001b[39m, n_epochs=\u001b[32m1\u001b[39m, optimizer=ndl.optim.SGD,\n\u001b[32m    181\u001b[39m               lr=\u001b[32m4.0\u001b[39m, weight_decay=\u001b[32m0.0\u001b[39m, loss_fn=nn.SoftmaxLoss, clip=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    182\u001b[39m               device=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    183\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    Performs {n_epochs} epochs of training.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \n\u001b[32m    186\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03m        model: LanguageModel instance\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m        data: data of shape (nbatch, batch_size) given from batchify function\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m        seq_len: i.e. bptt, sequence length\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03m        n_epochs: number of epochs (int)\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03m        optimizer: Optimizer class\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m        lr: learning rate (float)\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[33;03m        weight_decay: weight decay (float)\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[33;03m        loss_fn: nn.Module class\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[33;03m        clip: max norm of gradients (optional)\u001b[39;00m\n\u001b[32m    196\u001b[39m \n\u001b[32m    197\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03m        avg_acc: average accuracy over dataset from last epoch of training\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m        avg_loss: average loss over dataset from last epoch of training\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    201\u001b[39m     np.random.seed(\u001b[32m4\u001b[39m)\n\u001b[32m    203\u001b[39m     opt = optimizer(model.parameters(), lr, weight_decay)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/simple_training.py:152\u001b[39m, in \u001b[36mepoch_general_ptb\u001b[39m\u001b[34m(data, model, seq_len, loss_fn, opt, clip, device, dtype)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[32m    150\u001b[39m     x, target = ndl.data.get_batch(\n\u001b[32m    151\u001b[39m         data, i, seq_len, device=device, dtype=dtype)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     real_len = target.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    153\u001b[39m     total_example += real_len\n\u001b[32m    154\u001b[39m     out, last_time_h = model(x, last_time_h)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/autograd.py:296\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, out_grad)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, out_grad=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    291\u001b[39m     out_grad = (\n\u001b[32m    292\u001b[39m         out_grad\n\u001b[32m    293\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m out_grad\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m init.ones(*\u001b[38;5;28mself\u001b[39m.shape, dtype=\u001b[38;5;28mself\u001b[39m.dtype, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    295\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[43mcompute_gradient_of_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_grad\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/autograd.py:386\u001b[39m, in \u001b[36mcompute_gradient_of_variables\u001b[39m\u001b[34m(output_tensor, out_grad)\u001b[39m\n\u001b[32m    384\u001b[39m node.grad = adj_v\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node.is_leaf():\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     gradients = \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgradient_as_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node.inputs, gradients):\n\u001b[32m    388\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m node_to_output_grads_list:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/autograd.py:59\u001b[39m, in \u001b[36mOp.gradient_as_tuple\u001b[39m\u001b[34m(self, out_grad, node)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgradient_as_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, out_grad: \u001b[33m\"\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m\"\u001b[39m, node: \u001b[33m\"\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m\"\u001b[39m) -> Tuple[\u001b[33m\"\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     58\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Convenience method to always return a tuple from gradient call\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/ops.py:331\u001b[39m, in \u001b[36mExp.gradient\u001b[39m\u001b[34m(self, out_grad, node)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgradient\u001b[39m(\u001b[38;5;28mself\u001b[39m, out_grad, node):\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out_grad * \u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/ops.py:335\u001b[39m, in \u001b[36mexp\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexp\u001b[39m(a):\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/autograd.py:72\u001b[39m, in \u001b[36mTensorOp.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_from_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/autograd.py:242\u001b[39m, in \u001b[36mTensor.make_from_op\u001b[39m\u001b[34m(op, inputs)\u001b[39m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tensor.requires_grad:\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor.detach()\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealize_cached_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/autograd.py:99\u001b[39m, in \u001b[36mValue.realize_cached_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached_data\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# note: data implicitly calls realized cached data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[38;5;28mself\u001b[39m.cached_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealize_cached_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mself\u001b[39m.cached_data\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached_data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/ops.py:327\u001b[39m, in \u001b[36mExp.compute\u001b[39m\u001b[34m(self, a)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, a):\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/backend_ndarray/ndarray.py:758\u001b[39m, in \u001b[36mexp\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexp\u001b[39m(a):\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/../python/needle/backend_ndarray/ndarray.py:491\u001b[39m, in \u001b[36mNDArray.exp\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexp\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    490\u001b[39m     out = NDArray.make(\u001b[38;5;28mself\u001b[39m.shape, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mewise_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "train_ptb(model, train_data, seq_len=40, n_epochs=1, device=device)\n",
        "evaluate_ptb(model, train_data, seq_len=40, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import needle as ndl\n",
        "from models import LanguageModel\n",
        "import simple_training\n",
        "importlib.reload(simple_training)  # This forces reload of your changes\n",
        "from simple_training import train_ptb, evaluate_ptb\n",
        "\n",
        "device = ndl.cpu()\n",
        "corpus = ndl.data.Corpus(\"../data/ptb\")\n",
        "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=device, dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on device:  cpu()\n",
            "                                                                                \r"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'generator' object has no attribute 'set_postfix'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m importlib.reload(simple_training)  \u001b[38;5;66;03m# Reload to get your latest changes\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msimple_training\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_ptb, evaluate_ptb\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrain_ptb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/simple_training.py:208\u001b[39m, in \u001b[36mtrain_ptb\u001b[39m\u001b[34m(model, data, seq_len, n_epochs, optimizer, lr, weight_decay, loss_fn, clip, device, dtype)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m epoch_pbar:\n\u001b[32m    207\u001b[39m     start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     acc, loss = \u001b[43mepoch_general_ptb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m     end_time = time.time()\n\u001b[32m    212\u001b[39m     \u001b[38;5;66;03m# Update epoch progress with metrics\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/needle/apps/simple_training.py:169\u001b[39m, in \u001b[36mepoch_general_ptb\u001b[39m\u001b[34m(data, model, seq_len, loss_fn, opt, clip, device, dtype)\u001b[39m\n\u001b[32m    167\u001b[39m current_acc = right_num / total_example \u001b[38;5;28;01mif\u001b[39;00m total_example > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    168\u001b[39m current_loss = total_loss / total_example \u001b[38;5;28;01mif\u001b[39;00m total_example > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43mpbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_postfix\u001b[49m(loss=current_loss, acc=current_acc)\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt:\n\u001b[32m    172\u001b[39m     opt.reset_grad()\n",
            "\u001b[31mAttributeError\u001b[39m: 'generator' object has no attribute 'set_postfix'"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "importlib.reload(simple_training)  # Reload to get your latest changes\n",
        "from simple_training import train_ptb, evaluate_ptb\n",
        "train_ptb(model, train_data, seq_len=40, n_epochs=1, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "history_visible": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
